# LLM Bindings e Suporte a Arquivos Multim√≠dia

Este documento descreve como o Slack MCP integra com a API Decopilot do Mesh para processar mensagens com LLM e suporte a arquivos multim√≠dia (imagens e √°udio).

## Vis√£o Geral

O Slack MCP usa a API Decopilot do Mesh para processar mensagens de usu√°rios com modelos de linguagem. A integra√ß√£o suporta:

- ‚úÖ Streaming de respostas em tempo real
- ‚úÖ Anexos de imagem (vis√£o computacional)
- ‚úÖ Anexos de √°udio (transcri√ß√£o e an√°lise)
- ‚úÖ Contexto de conversa√ß√£o
- ‚úÖ Agentes personalizados
- ‚úÖ M√∫ltiplos provedores de LLM (Anthropic, OpenAI, etc.)

## Fluxo de Processamento

### 1. Recebimento de Mensagem

Quando uma mensagem chega do Slack:

```typescript
// EventHandler detecta mensagem com anexos
const media = await processAttachedFiles(files);
```

### 2. Download de Arquivos Multim√≠dia

Arquivos (imagens e √°udio) s√£o baixados do Slack e convertidos para base64:

```typescript
// slack-client.ts - processSlackFiles()
const downloaded = await downloadSlackFile(file.url_private, file.mimetype);

return {
  type: isAudio ? "audio" : "image",  // Detecta automaticamente
  data: downloaded.data,              // Base64
  mimeType: downloaded.mimeType,      // audio/mp4, image/png, etc.
  name: file.name,                    // Nome original do arquivo
};
```

**Tipos de arquivo suportados:**
- **Imagens**: `image/png`, `image/jpeg`, `image/gif`, `image/webp`
- **√Åudio**: `audio/mp4`, `audio/mpeg`, `audio/ogg`, `audio/webm`, `audio/wav`
- **Documentos**: `application/pdf`, `application/vnd.openxmlformats-officedocument.wordprocessingml.document` (DOCX)
- **Texto**: `text/plain`, `application/json`, `.txt`, `.json`, `.csv`, `.md`, `.js`, `.ts`, `.py`, etc.

### 2.1. Extra√ß√£o de Texto de Documentos

Para **PDF** e **DOCX**, o texto √© extra√≠do automaticamente usando bibliotecas especializadas:

```typescript
// slack-client.ts - extractTextFromPDF()
import * as pdfParse from "pdf-parse";

const data = await pdfParse(buffer);
return data.text;  // Texto extra√≠do do PDF
```

```typescript
// slack-client.ts - extractTextFromDOCX()
import mammoth from "mammoth";

const result = await mammoth.extractRawText({ buffer });
return result.value;  // Texto extra√≠do do DOCX
```

**Limita√ß√µes:**
- ‚úÖ **Texto puro** extra√≠do com sucesso
- ‚úÖ M√°ximo **500KB** de texto ap√≥s extra√ß√£o
- ‚ùå **Imagens** dentro do PDF/DOCX n√£o s√£o processadas
- ‚ùå **Tabelas** complexas podem perder formata√ß√£o
- ‚ö†Ô∏è Arquivos muito grandes (>1.5MB) podem ser truncados

**Logs esperados:**
```bash
[Slack] üìÑ Extracting text from PDF: documento.pdf
[Slack] üìÑ Downloaded text file: documento.pdf (application/pdf, 12345 chars)

[Slack] üìÑ Extracting text from DOCX: contrato.docx
[Slack] üìÑ Downloaded text file: contrato.docx (application/vnd.openxmlformats-officedocument.wordprocessingml.document, 67890 chars)
```

### 2.2. Processamento de Arquivos de Texto

Arquivos de texto puro (JSON, TXT, c√≥digo-fonte) s√£o baixados diretamente:

```typescript
// slack-client.ts - downloadTextFile()
const text = await response.text();

if (text.length > maxSize) {
  return text.substring(0, maxSize) + "\n\n[... truncated]";
}
return text;
```

**Formatos suportados:**
- `text/plain` ‚Üí `.txt`, `.log`, `.env`
- `application/json` ‚Üí `.json`
- `text/csv` ‚Üí `.csv`
- `text/markdown` ‚Üí `.md`, `.markdown`
- C√≥digo-fonte: `.js`, `.ts`, `.tsx`, `.jsx`, `.py`, `.rb`, `.go`, `.java`, `.c`, `.cpp`, `.rs`, `.sh`, etc.

**Como s√£o enviados ao LLM:**
```typescript
// lib/llm.ts - messagesToPrompt()
if (msg.textFiles && msg.textFiles.length > 0) {
  for (const file of msg.textFiles) {
    parts.push({ 
      type: "text", 
      text: `\n\n[File: ${file.name}]\n\`\`\`${file.language}\n${file.content}\n\`\`\`` 
    });
  }
}
```

**Exemplo de prompt gerado:**
```
Analise este arquivo JSON

[File: config.json]
```json
{
  "version": "1.0.0",
  "settings": {...}
}
```
```

### 3. Constru√ß√£o do Prompt

Mensagens s√£o convertidas para o formato da API Decopilot:

```typescript
// lib/llm.ts - messagesToPrompt()
const prompt = [
  {
    id: "msg_<timestamp>_<random>",
    role: "user",
    parts: [
      { type: "text", text: "O que tem nesta imagem?" },
      { 
        type: "file",
        url: "data:image/png;base64,iVBORw0KGgo...",
        filename: "image",
        mediaType: "image/png"
      }
    ]
  }
];
```

## Formato de Mensagens

### Estrutura de UIMessage

Cada mensagem segue o formato `UIMessage` do Vercel AI SDK:

```typescript
interface UIMessage {
  id: string;                    // ID √∫nico obrigat√≥rio
  role: "user" | "assistant" | "system";
  parts: UIMessagePart[];        // Array de partes (texto, arquivos, etc.)
  metadata?: unknown;            // Metadados opcionais
}
```

### Tipos de Parts

#### Texto

```typescript
{
  type: "text",
  text: "Conte√∫do da mensagem"
}
```

#### Imagem/Arquivo

```typescript
{
  type: "file",
  url: "data:image/png;base64,<base64_data>",
  filename: "image",
  mediaType: "image/png"
}
```

**IMPORTANTE:** 
- O `type` deve ser `"file"` (n√£o `"image"` ou `"data-url"`)
- O `url` deve ser um data URI completo com o prefixo `data:${mimeType};base64,`
- Inclua `filename` e `mediaType` obrigatoriamente

### Suporte a √Åudio

**‚ö†Ô∏è Importante: √Åudios N√ÉO s√£o enviados diretamente ao LLM!**

O bot usa a binding do **OpenAI Whisper** para transcrever √°udios e enviar **apenas o texto** ao LLM. √Åudio em base64 n√£o √© suportado nativamente pela maioria dos LLMs.

**Como funciona:**

1. ‚úÖ Usu√°rio envia √°udio no Slack
2. ‚úÖ Bot baixa o arquivo via Slack API
3. ‚úÖ Armazena temporariamente em servidor local (TTL: 10min)
4. ‚úÖ Gera URL p√∫blica via t√∫nel: `https://localhost-xxx.deco.host/temp-files/{id}`
5. ‚úÖ **Whisper API transcreve** o √°udio
6. ‚úÖ **Transcri√ß√£o (texto puro)** √© adicionada ao prompt
7. ‚úÖ LLM recebe APENAS o texto (n√£o recebe √°udio)

**Formatos suportados pelo Whisper:**
- `audio/flac`, `audio/m4a`, `audio/mp3`, `audio/mp4`
- `audio/mpeg`, `audio/mpga`, `audio/oga`, `audio/ogg`
- `audio/wav`, `audio/webm`

**Configura√ß√£o:**
```typescript
// No Mesh Admin, adicionar binding:
WHISPER: "@deco/whisper"

// Opcional: Definir URL p√∫blica do servidor
SERVER_PUBLIC_URL: "https://localhost-xxx.deco.host"
```

**Vantagens:**
- ‚úÖ Transcri√ß√£o r√°pida e precisa (57+ idiomas)
- ‚úÖ Funciona mesmo que Slack n√£o gere transcri√ß√£o
- ‚úÖ LLM pode processar o texto normalmente
- ‚úÖ Suporta contexto de conversa√ß√£o com √°udio
- ‚úÖ √Åudio √© automaticamente limpo ap√≥s 10 minutos

**Logs esperados:**
```bash
[EventHandler] Audio file for transcription: {
  name: "audio_message.m4a",
  mimeType: "audio/mp4",
  tempFileUrl: "https://localhost-xxx.deco.host/temp-files/abc-123..."
}
[EventHandler] ‚úÖ Transcription received: "Ol√°, como vai?"
[LLM] Adding transcription to prompt: [Audio: audio_message.m4a] Ol√°, como vai?
```

**Sem Whisper:**
Se a binding n√£o estiver configurada e o usu√°rio enviar √°udio, o bot responder√° com:
```
üé§ √Åudio detectado! Para processar arquivos de √°udio, √© necess√°rio 
ativar a integra√ß√£o Whisper no Mesh.

Entre em contato com o administrador para configurar o Whisper 
e habilitar transcri√ß√£o autom√°tica de √°udios.
```

O √°udio **n√£o ser√° processado** at√© que o Whisper seja configurado.

## API Decopilot

### Endpoint

```
POST /api/{organizationId}/decopilot/stream
```

### Request Body

```typescript
{
  messages: UIMessage[],
  model: {
    id: "anthropic/claude-sonnet-4.5",
    connectionId: "conn_xxx"
  },
  agent: {
    id: "vir_xxx" | null
  },
  stream: true,  // Para respostas em streaming
  temperature?: number
}
```

### Headers

```typescript
{
  "Content-Type": "application/json",
  "Authorization": "Bearer <meshToken>",
  "Accept": "application/json, text/event-stream"  // Obrigat√≥rio para streaming
}
```

## Streaming de Respostas

### Tipos de Eventos

A API Decopilot retorna eventos Server-Sent Events (SSE):

- `start` - In√≠cio do streaming
- `start-step` - In√≠cio de um passo
- `text-start` - In√≠cio de texto
- `text-delta` - Fragmento de texto
- `text-end` - Fim de texto
- `finish-step` - Fim de um passo
- `finish` - Fim do streaming
- `message-metadata` - Metadados da mensagem

### Processamento

```typescript
// lib/llm.ts - generateLLMResponseWithStreaming()
const reader = response.body
  .pipeThrough(new TextDecoderStream())
  .getReader();

let buffer = "";
let textContent = "";

while (!finished) {
  const { done, value } = await reader.read();
  if (done) break;
  
  buffer += value;
  const lines = buffer.split("\n");
  buffer = lines.pop() ?? "";
  
  for (const line of lines) {
    const parsed = parseStreamLine(line);
    
    if (parsed?.type === "text-delta") {
      textContent += parsed.delta;
      await onStream(textContent, false);
    } else if (parsed?.type === "finish") {
      finished = true;
      break;
    }
  }
}
```

### Rate Limiting

Para evitar sobrecarga de updates no Slack:

```typescript
const STREAM_UPDATE_INTERVAL = 500; // ms
let lastStreamUpdate = 0;

if (now - lastStreamUpdate > STREAM_UPDATE_INTERVAL) {
  await onStream(textContent, false);
  lastStreamUpdate = now;
}
```

## Contexto de Conversa√ß√£o

### Estrutura

O contexto mant√©m as √∫ltimas mensagens da conversa:

```typescript
// slack/utils/contextBuilder.ts
const messages = await buildLLMMessages(
  channel,
  text,
  ts,
  threadTs,
  images
);
```

### Formato do Contexto

```typescript
[
  {
    id: "msg_xxx",
    role: "user",
    parts: [{ type: "text", text: "<previous_conversation>..." }]
  },
  // ... mensagens anteriores
  {
    id: "msg_xxx",
    role: "user",
    parts: [{ type: "text", text: "<end_previous_conversation>" }]
  },
  {
    id: "msg_xxx",
    role: "user",
    parts: [
      { type: "text", text: "<current_request>Pergunta atual</current_request>" },
      { type: "file", url: "data:image/...", filename: "image", mediaType: "image/png" }
    ]
  }
]
```

## Configura√ß√£o

### Vari√°veis de Ambiente

```typescript
{
  meshUrl: "http://localhost:3000",
  organizationId: "org_xxx",
  modelProviderId: "conn_xxx",
  modelId: "anthropic/claude-sonnet-4.5",
  agentId: "vir_xxx",
  meshToken: "Bearer xxx"
}
```

### Inicializa√ß√£o

```typescript
// main.ts
configureLLM(
  config.modelId || DEFAULT_LANGUAGE_MODEL,
  config.systemPrompt
);
```

## Troubleshooting

### Problema: Imagens n√£o s√£o reconhecidas pela LLM

**Solu√ß√£o:** Verifique se o formato est√° correto:

```typescript
// ‚úÖ CORRETO
{
  type: "file",
  url: "data:image/png;base64,...",
  filename: "image",
  mediaType: "image/png"
}

// ‚ùå ERRADO
{
  type: "image",          // tipo incorreto
  image: "data:...",      // campo incorreto
  mimeType: "image/png"   // nome de campo incorreto
}
```

### Problema: Erro "must start with 'data-'"

**Causa:** Tipo de part incorreto.

**Solu√ß√£o:** Use `type: "file"` em vez de `"data-url"` ou `"data-image"`.

### Problema: 406 Not Acceptable

**Causa:** Header `Accept` faltando.

**Solu√ß√£o:** Adicione o header:
```typescript
Accept: "application/json, text/event-stream"
```

### Problema: Erro de valida√ß√£o "expected string, received undefined" no campo "id"

**Causa:** Mensagens sem campo `id`.

**Solu√ß√£o:** Gere IDs √∫nicos para cada mensagem:
```typescript
const generateMessageId = () => {
  const timestamp = Date.now();
  const random = Math.random().toString(36).substring(2, 11);
  return `msg_${timestamp}_${random}`;
};
```

## Refer√™ncias

- [Vercel AI SDK - UIMessage](https://sdk.vercel.ai/docs)
- [Mesh Decopilot API](../admin-sites/apps/mesh/src/api/routes/decopilot/)
- [Slack File Uploads](https://api.slack.com/types/file)

## Exemplo Completo

```typescript
// Enviar mensagem com imagem para LLM
const response = await fetch(
  `${meshUrl}/api/${organizationId}/decopilot/stream`,
  {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      "Authorization": `Bearer ${token}`,
      "Accept": "application/json, text/event-stream"
    },
    body: JSON.stringify({
      messages: [
        {
          id: "msg_1234567890_abc123",
          role: "user",
          parts: [
            { 
              type: "text", 
              text: "Analise esta imagem" 
            },
            {
              type: "file",
              url: "data:image/png;base64,iVBORw0KGgo...",
              filename: "screenshot.png",
              mediaType: "image/png"
            }
          ]
        }
      ],
      model: {
        id: "anthropic/claude-sonnet-4.5",
        connectionId: "conn_xxx"
      },
      agent: {
        id: "vir_xxx"
      },
      stream: true
    })
  }
);

// Processar stream
const reader = response.body
  .pipeThrough(new TextDecoderStream())
  .getReader();

let textContent = "";
let buffer = "";

while (true) {
  const { done, value } = await reader.read();
  if (done) break;
  
  buffer += value;
  const lines = buffer.split("\n");
  buffer = lines.pop() ?? "";
  
  for (const line of lines) {
    if (line.startsWith("data: ")) {
      const data = JSON.parse(line.slice(6));
      
      if (data.type === "text-delta") {
        textContent += data.delta;
        console.log(textContent);
      } else if (data.type === "finish") {
        return textContent;
      }
    }
  }
}
```

## Logs √öteis

Para debug, ative os logs:

```typescript
console.log("[LLM] Calling Decopilot API:", {
  url,
  hasToken: !!token,
  modelId,
  hasAgent: !!agentId,
  stream: true,
  messageCount: messages.length,
  hasImages: messages.some(m => 
    m.parts.some(p => p.type === "file")
  )
});
```

