# Mudan√ßas de Otimiza√ß√£o - Slack MCP

## üìã Resumo das Mudan√ßas

Este documento descreve as otimiza√ß√µes implementadas no Slack MCP para melhorar a confiabilidade, reduzir o uso de recursos e simplificar a arquitetura em produ√ß√£o.

**Data:** 28 de Janeiro de 2026

---

## ‚úÖ 1. Remo√ß√£o do DATABASE Binding

### Problema
O binding `DATABASE` estava declarado no `StateSchema` mas nunca era utilizado pelo c√≥digo (0 refer√™ncias encontradas).

### Solu√ß√£o
Removido o binding n√£o utilizado do schema de configura√ß√£o.

**Arquivo modificado:** `server/types/env.ts`

```typescript
// ANTES
export const StateSchema = z.object({
  EVENT_BUS: BindingOf("@deco/event-bus").optional(),
  DATABASE: BindingOf("@deco/postgres").optional(), // ‚ùå Nunca usado
  MODEL_PROVIDER: BindingOf("@deco/llm")...
});

// DEPOIS
export const StateSchema = z.object({
  EVENT_BUS: BindingOf("@deco/event-bus").optional(),
  MODEL_PROVIDER: BindingOf("@deco/llm")... // ‚úÖ Mais limpo
});
```

### Impacto
- ‚úÖ Schema mais limpo e f√°cil de entender
- ‚úÖ Menos confus√£o para desenvolvedores
- ‚úÖ Interface de configura√ß√£o do Mesh simplificada

---

## ‚úÖ 2. Corre√ß√£o de Memory Leak no API Key Manager

### Problema
O `Map` de API keys persistentes crescia indefinidamente sem limpeza, causando:
- Memory leak em servidores long-running
- API keys perdidas ap√≥s restart (n√£o sobreviviam a rein√≠cios)

### Solu√ß√£o
Implementadas duas novas fun√ß√µes:

#### 2.1. `loadApiKeyFromKV`
Carrega API keys do KV store ap√≥s restart do servidor.

```typescript
export async function loadApiKeyFromKV(
  connectionId: string,
  getConfigFn: (id: string) => Promise<{ meshToken?: string } | null>
): Promise<string | null> {
  // 1. Verifica cache em mem√≥ria
  const cached = persistentApiKeys.get(connectionId);
  if (cached) return cached;
  
  // 2. Tenta carregar do KV (sobrevive a restarts)
  const config = await getConfigFn(connectionId);
  if (config?.meshToken) {
    persistentApiKeys.set(connectionId, config.meshToken);
    console.log(`[API-KEY] Loaded from KV for ${connectionId}`);
    return config.meshToken;
  }
  
  return null;
}
```

#### 2.2. `cleanupOrphanedKeys`
Remove API keys de conex√µes que n√£o existem mais (cleanup peri√≥dico).

```typescript
export async function cleanupOrphanedKeys(
  getConfigFn: (id: string) => Promise<any | null>
): Promise<number> {
  let cleaned = 0;
  for (const [connectionId] of persistentApiKeys) {
    const config = await getConfigFn(connectionId);
    if (!config) {
      persistentApiKeys.delete(connectionId);
      cleaned++;
    }
  }
  if (cleaned > 0) {
    console.log(`[API-KEY] Cleaned ${cleaned} orphaned keys`);
  }
  return cleaned;
}
```

#### 2.3. Integra√ß√£o no `main.ts`
```typescript
// Tenta carregar API key do KV primeiro (survive restarts)
let apiKey = await loadApiKeyFromKV(connectionId, readConnectionConfig);

// Se n√£o encontrada, cria uma nova
if (!apiKey) {
  apiKey = await getOrCreatePersistentApiKey({
    meshUrl, organizationId, connectionId, temporaryToken
  });
}

// Cleanup peri√≥dico a cada 1 hora
setInterval(async () => {
  console.log("[API-KEY] Running periodic cleanup...");
  await cleanupOrphanedKeys(readConnectionConfig);
}, 60 * 60 * 1000);
```

**Arquivos modificados:**
- `shared/api-key-manager.ts` - Novas fun√ß√µes
- `slack-mcp/server/main.ts` - Integra√ß√£o e cleanup

### Impacto
- ‚úÖ API keys sobrevivem a restarts (recovery autom√°tico)
- ‚úÖ Memory leak corrigido (cleanup peri√≥dico)
- ‚úÖ Mais confi√°vel em produ√ß√£o

---

## ‚úÖ 3. Otimiza√ß√£o do KV Store Cleanup

### Problema
- Cleanup rodava a cada 5 minutos (muitos I/O)
- Sem limite m√°ximo de entradas (risco de crescimento infinito)
- Logs sem m√©tricas √∫teis

### Solu√ß√£o

#### 3.1. Intervalo Aumentado
```typescript
// ANTES
const CLEANUP_INTERVAL = 5 * 60 * 1000; // 5 minutos

// DEPOIS
const CLEANUP_INTERVAL = 15 * 60 * 1000; // 15 minutos (-66% I/O)
```

#### 3.2. Limite M√°ximo com Alertas
```typescript
const MAX_ENTRIES = 10_000; // Limite recomendado

async cleanup(): Promise<number> {
  // ... limpeza de expirados ...
  
  // Verifica limite
  const sizeAfter = this.store.size;
  if (sizeAfter > MAX_ENTRIES) {
    console.warn(
      `[KV] ‚ö†Ô∏è Store size (${sizeAfter}) exceeds recommended limit (${MAX_ENTRIES}). ` +
      `Consider adjusting TTLs or archiving old data.`
    );
  }
  
  // Log com m√©tricas
  if (cleaned > 0) {
    console.log(
      `[KV] üßπ Cleanup: ${cleaned} expired entries removed (${sizeBefore} ‚Üí ${sizeAfter})`
    );
  }
  
  return cleaned;
}
```

#### 3.3. Fun√ß√£o para Monitoramento
```typescript
export function getKvStoreSize(): number {
  return kvStore?.getSize() ?? 0;
}
```

**Arquivo modificado:** `server/lib/kv.ts`

### Impacto
- ‚úÖ -66% de opera√ß√µes de I/O (15min vs 5min)
- ‚úÖ Alertas quando limite √© excedido
- ‚úÖ M√©tricas detalhadas no cleanup
- ‚úÖ Fun√ß√£o exposta para health check

---

## ‚úÖ 4. Simplifica√ß√£o do EVENT_BUS

### Problema
O `EVENT_BUS` binding estava sendo usado **incorretamente** como fallback quando o LLM n√£o estava configurado, enviando eventos que nunca eram consumidos.

### Solu√ß√£o

#### 4.1. Mantido no Schema (Opcional)
```typescript
// MANTIDO para usos leg√≠timos (rea√ß√µes, canais, etc.)
EVENT_BUS: BindingOf("@deco/event-bus").optional()
```

#### 4.2. Removido Uso Incorreto
Substitu√≠das 3 chamadas de `publishToEventBus()` (fallback) por mensagens amig√°veis:

```typescript
// ANTES
if (!isLLMConfigured()) {
  await publishToEventBus(
    SLACK_EVENT_TYPES.OPERATOR_GENERATE,
    messages,
    { channel, threadTs, messageTs, userId },
    meshConfig,
  );
  return;
}

// DEPOIS
if (!isLLMConfigured()) {
  const warningMsg =
    "‚ö†Ô∏è Por favor, configure um LLM (Language Model) no Mesh para usar o bot.\n\n" +
    "Acesse as configura√ß√µes da conex√£o no Mesh e selecione um provedor de modelo (como OpenAI, Anthropic, etc.).";
  
  await replyInThread(channel, threadTs, warningMsg);
  
  // Deleta mensagem de "pensando..." se existir
  if (thinkingMsg?.ts) {
    await deleteMessage(channel, thinkingMsg.ts);
  }
  
  console.log("[EventHandler] LLM not configured - sent configuration warning");
  return;
}
```

#### 4.3. Removida Fun√ß√£o `publishToEventBus`
A fun√ß√£o de fallback foi completamente removida do c√≥digo.

**Arquivos modificados:**
- `server/slack/handlers/eventHandler.ts` - 3 substitui√ß√µes + fun√ß√£o removida

**Mantido:**
- `server/events.ts` - Ainda usado para eventos leg√≠timos (rea√ß√µes, canais criados, etc.)
- `EVENT_BUS` binding - Opcional no schema para usos futuros

### Impacto
- ‚úÖ UX melhorado: mensagens claras quando LLM n√£o configurado
- ‚úÖ Menos eventos in√∫teis no Event Bus
- ‚úÖ C√≥digo mais limpo e f√°cil de entender
- ‚úÖ EVENT_BUS dispon√≠vel para usos leg√≠timos

---

## ‚úÖ 5. Health Check Endpoint

### Problema
Sem endpoint de monitoramento para Kubernetes/produ√ß√£o, dificultando:
- Liveness probes
- Readiness probes
- Debugging de problemas em produ√ß√£o

### Solu√ß√£o
Criado endpoint `/health` com m√©tricas do sistema.

#### 5.1. Nova Fun√ß√£o de Health Status
**Arquivo:** `server/health.ts`

```typescript
export async function getHealthStatus(): Promise<HealthStatus> {
  const kvHealthy = await checkKvHealth();
  const memUsage = process.memoryUsage();

  return {
    status: kvHealthy ? "ok" : "degraded",
    uptime: process.uptime(),
    memory: {
      heapUsed: memUsage.heapUsed,
      heapTotal: memUsage.heapTotal,
      external: memUsage.external,
      rss: memUsage.rss,
    },
    metrics: {
      apiKeysCount: getApiKeysCount(),
      kvStoreSize: getKvStoreSize(),
    },
    database: {
      connected: kvHealthy,
      type: "kv-store-local",
    },
  };
}
```

#### 5.2. Rota Atualizada
**Arquivo:** `server/router.ts`

```typescript
// ANTES
app.get("/health", (c) => {
  return c.json({ status: "ok", service: "slack-mcp" });
});

// DEPOIS
app.get("/health", async (c) => {
  const health = await getHealthStatus();
  const statusCode = health.status === "ok" ? 200 : 503;
  return c.json(health, statusCode);
});
```

#### 5.3. Exemplo de Resposta
```json
{
  "status": "ok",
  "uptime": 3600.5,
  "memory": {
    "heapUsed": 45678912,
    "heapTotal": 67108864,
    "external": 1234567,
    "rss": 89012345
  },
  "metrics": {
    "apiKeysCount": 3,
    "kvStoreSize": 15
  },
  "database": {
    "connected": true,
    "type": "kv-store-local"
  }
}
```

**Arquivos criados/modificados:**
- `server/health.ts` - Novo arquivo
- `server/router.ts` - Rota atualizada

### Impacto
- ‚úÖ Kubernetes liveness/readiness probes
- ‚úÖ Monitoramento de mem√≥ria e recursos
- ‚úÖ Visibilidade do estado do sistema
- ‚úÖ HTTP 503 quando degraded (K8s restart autom√°tico)

---

## üìä Resumo do Impacto

| M√©trica | Antes | Depois | Melhoria |
|---------|-------|--------|----------|
| **Bindings no Schema** | 6 | 5 | -16% (mais limpo) |
| **API Key recovery** | ‚ùå Perde no restart | ‚úÖ Recarrega do KV | Confi√°vel |
| **Memory leak risk** | ‚ö†Ô∏è Alto (Map infinito) | ‚úÖ Baixo (cleanup) | Est√°vel |
| **KV cleanup I/O** | A cada 5min | A cada 15min | -66% I/O |
| **EVENT_BUS fallback** | ‚ùå Eventos in√∫teis | ‚úÖ Mensagens claras | UX melhor |
| **Health monitoring** | ‚ùå Nenhum | ‚úÖ Endpoint completo | Observabilidade |
| **Alertas** | ‚ùå Nenhum | ‚úÖ KV size limit | Proativo |

---

## üîÑ Como Testar

### 1. API Key Recovery
```bash
# Terminal 1: Inicie o servidor
bun run dev

# Terminal 2: Configure uma conex√£o no Mesh UI
# Aguarde configura√ß√£o ser salva

# Terminal 1: Ctrl+C e reinicie
bun run dev

# Resultado: API key deve ser recarregada automaticamente
# Log esperado: [API-KEY] Loaded from KV for conn_xxx
```

### 2. KV Cleanup
```bash
# Verifique logs a cada 15 minutos
[KV] üßπ Cleanup: 2 expired entries removed (150 ‚Üí 148)

# Teste limite m√°ximo (adicione 10k+ entradas)
[KV] ‚ö†Ô∏è Store size (10001) exceeds recommended limit (10000). Consider adjusting TTLs or archiving old data.
```

### 3. EVENT_BUS (LLM n√£o configurado)
```
Usu√°rio: @bot ol√°
Bot: ‚ö†Ô∏è Por favor, configure um LLM (Language Model) no Mesh para usar o bot.

Acesse as configura√ß√µes da conex√£o no Mesh e selecione um provedor de modelo (como OpenAI, Anthropic, etc.).
```

### 4. Health Check
```bash
curl http://localhost:3003/health

# Resposta esperada (status 200):
{
  "status": "ok",
  "uptime": 123.45,
  "metrics": {
    "apiKeysCount": 2,
    "kvStoreSize": 8
  }
}
```

### 5. API Key Cleanup
```bash
# Aguarde 1 hora ou force:
# (Deletar config de uma conex√£o e esperar cleanup)

# Log esperado:
[API-KEY] Running periodic cleanup...
[API-KEY] Cleaned 1 orphaned keys
```

---

## üöÄ Deploy em Produ√ß√£o

### Kubernetes Probes
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: slack-mcp
spec:
  template:
    spec:
      containers:
      - name: slack-mcp
        image: slack-mcp:latest
        livenessProbe:
          httpGet:
            path: /health
            port: 3003
          initialDelaySeconds: 10
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /health
            port: 3003
          initialDelaySeconds: 5
          periodSeconds: 10
```

### Monitoramento Recomendado
1. **Health endpoint**: Monitor status != "ok"
2. **KV size**: Alert quando > 9000 (90% do limite)
3. **API Keys**: Alert se count > 100 (poss√≠vel leak)
4. **Memory**: Alert se rss > 500MB (memory leak)
5. **Cleanup logs**: Alert se cleanup falhar por 3x consecutivas

---

## üìù Pr√≥ximos Passos (Opcional)

### Curto Prazo
- [ ] Adicionar rate limiting no health endpoint
- [ ] Expor m√©tricas Prometheus (`/metrics`)
- [ ] Adicionar traces OpenTelemetry

### Longo Prazo
- [ ] Migrar KV Store para PostgreSQL (multi-pod K8s)
- [ ] Implementar Redis cache (30s TTL) para reads
- [ ] Adicionar criptografia de dados no KV store
- [ ] Implementar backup autom√°tico do KV store

---

## ‚úÖ Conclus√£o

Todas as mudan√ßas do plano de otimiza√ß√£o foram implementadas com sucesso:

1. ‚úÖ DATABASE binding removido
2. ‚úÖ API Key Manager corrigido (recovery + cleanup)
3. ‚úÖ KV Store otimizado (intervalo + limite + m√©tricas)
4. ‚úÖ EVENT_BUS simplificado (fallback removido, mantido para usos leg√≠timos)
5. ‚úÖ Health Check endpoint criado

O Slack MCP agora est√° mais **confi√°vel**, **eficiente** e **observ√°vel** em produ√ß√£o! üéâ

